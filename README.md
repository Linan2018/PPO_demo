# PPO_demo

# Requirement
- tensorflow >= 1.2
- gym

## Setup
```
python main.py -s settings.json
```
![](https://github.com/Linan2018/PPO_demo/blob/master/result.png)
